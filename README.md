# beta_nmf: NMF with beta-divergence

Theano based GPGPU implementation of NMF with beta-diveregence and multiplicative updates.


## Dependencies

beta_nmf need Python >= 2.7, numpy >= 10.1, Theano >= 0.8, scikit-learn >= 0.17.1 and h5py >= 2.5

## Documentation

Documentation available at http://rserizel.github.io/beta_nmf/

## Getting Started

A short example is available as a [notebook]

<<<<<<< HEAD
<<<<<<< HEAD
[notebook]: https://github.com/rserizel/beta_nmf/blob/master/BetaNMF_howto.ipynb

=======
[notebook]: https://github.com/rserizel/beta_nmf/BetaNMF_howto.ipynb
>>>>>>> origin/master
=======
[notebook]: https://github.com/rserizel/beta_nmf/blob/master/BetaNMF_howto.ipynb
>>>>>>> origin/master

## Citation

If you are using this source code please consider citing the following paper: 

> R. Serizel, S. Essid, and G. Richard. “Mini-batch stochastic approaches for accelerated multiplicative updates in nonnegative matrix factorisation with beta-divergence”. Accepted for publication In *Proc. of MLSP*, p. 5, 2016.

Bibtex
```
	@inproceedings{serizel2016batch,
  	title={Mini-batch stochastic approaches for accelerated multiplicative updates in nonnegative matrix factorisation with beta-divergence},
  	author={Serizel, Romain and Essid, Slim and Richard, Ga{\"e}l},
  	booktitle={IEEE International Workshop on Machine Learning for Signal Processing (MLSP)},
  	pages={5},
  	year={2016},
  	organization={IEEE}
	}
```

## Author

Romain Serizel, 2015 -- Present
